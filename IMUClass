{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "\n",
    "# **Project 1: Classification of Time Series Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Name: Haneen Alsuradi\n",
    "NetID: hha243"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In this project, I will use 1 dimensional convolotional network to perform classification on time series data. Data is taken from Kaggle competition [Surface Type Classification] found in the link below: https://www.kaggle.com/c/career-con-2019/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## **Step 1: Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The first step is to import, view and prepare the data. We import the data saved in X_train.csv and y_train.csv. We split the data to train and test as advised. After that, we view the data using the head() command from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id  series_id  measurement_number  orientation_X  orientation_Y  \\\n",
       "0    0_0          0                   0       -0.75853       -0.63435   \n",
       "1    0_1          0                   1       -0.75853       -0.63434   \n",
       "2    0_2          0                   2       -0.75853       -0.63435   \n",
       "3    0_3          0                   3       -0.75852       -0.63436   \n",
       "4    0_4          0                   4       -0.75852       -0.63435   \n",
       "\n",
       "   orientation_Z  orientation_W  angular_velocity_X  angular_velocity_Y  \\\n",
       "0       -0.10488       -0.10597            0.107650            0.017561   \n",
       "1       -0.10490       -0.10600            0.067851            0.029939   \n",
       "2       -0.10492       -0.10597            0.007275            0.028934   \n",
       "3       -0.10495       -0.10597           -0.013053            0.019448   \n",
       "4       -0.10495       -0.10596            0.005135            0.007652   \n",
       "\n",
       "   angular_velocity_Z  linear_acceleration_X  linear_acceleration_Y  \\\n",
       "0            0.000767               -0.74857                 2.1030   \n",
       "1            0.003385                0.33995                 1.5064   \n",
       "2           -0.005978               -0.26429                 1.5922   \n",
       "3           -0.008974                0.42684                 1.0993   \n",
       "4            0.005245               -0.50969                 1.4689   \n",
       "\n",
       "   linear_acceleration_Z  \n",
       "0                -9.7532  \n",
       "1                -9.4128  \n",
       "2                -8.7267  \n",
       "3               -10.0960  \n",
       "4               -10.4410  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read Kaggle datasets\n",
    "X_train = pd.read_csv('/kaggle/input/career-con-2019/X_train.csv')\n",
    "y_train = pd.read_csv('/kaggle/input/career-con-2019/y_train.csv')\n",
    "# split X_train\n",
    "samples = 20\n",
    "time_series = 128\n",
    "start_x = X_train.shape[0] - samples*time_series\n",
    "X_train_new, X_test_new = X_train.iloc[:start_x], X_train.iloc[start_x:]\n",
    "# split y_train\n",
    "start_y = y_train.shape[0] - samples\n",
    "y_train_new, y_test_new = y_train.iloc[:start_y], y_train.iloc[start_y:]\n",
    "X_train_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "As can be noticed, the first 3 columns are not part of the features and must be dropped. We drop these columns for X_train_new and X_test_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "X_train_new=X_train_new.drop(['row_id', 'series_id','measurement_number'], axis=1)\n",
    "X_test_new=X_test_new.drop(['row_id', 'series_id','measurement_number'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Now, we have a look at the labels of the training data saved in y_train_new. We are only interested in the surface type which is the last column. We drop the other columns from y_train_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id        surface\n",
       "0          0        13  fine_concrete\n",
       "1          1        31       concrete\n",
       "2          2        20       concrete\n",
       "3          3        31       concrete\n",
       "4          4        22     soft_tiles"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We drop the first two columns from the y_train_new and y_test_new as they will not be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_new=y_train_new.drop(['series_id', 'group_id'], axis=1)\n",
    "y_test_new=y_test_new.drop(['series_id', 'group_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Now, we convert the dataframes to a numpy array. We extract the values from the data frame using .values. We print the shape of training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X_train_new: (485120, 10)\n",
      "The size of X_test_new: (2560, 10)\n",
      "The size of y_train_new: (3790, 1)\n",
      "The size of y_test_new: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_new=X_train_new.values\n",
    "X_test_new=X_test_new.values\n",
    "y_train_new=y_train_new.values\n",
    "y_test_new=y_test_new.values\n",
    "print('The size of X_train_new:', X_train_new.shape )\n",
    "print('The size of X_test_new:', X_test_new.shape )\n",
    "\n",
    "print('The size of y_train_new:', y_train_new.shape )\n",
    "print('The size of y_test_new:', y_test_new.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Now, we convert the strings (concrete, tiled, soft_tiels, ..etc.) in y_train_new and y_test_new to integer labels: 0,1,2... etc using the LabelEncorder function. After that we implement one hot coding using the to_categorical function. We have 9 types of surfaces and thus the number of cloumns for y_train_new and y_test_new  will be 9. One hot coding is suitable for 1D conv net models to prevent poor performance or unexpected results (predictions halfway between categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of y_train_new: (3790, 9)\n",
      "The shape of y_test_new: (20, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "y=np.concatenate([y_train_new,y_test_new])\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "y=to_categorical(y)\n",
    "\n",
    "\n",
    "y_train_new = y[:-20]\n",
    "y_test_new = y[-20:]\n",
    "print('The shape of y_train_new:', y_train_new.shape)\n",
    "print('The shape of y_test_new:', y_test_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We think that the orientation of the robot moving across surfaces is not a relevant information to predict the surface type. Instead, the rate of change of the roll, yaw and pitch can serve as better features for prediction. The rate of change can be affected by the way the robot moves which is directly affected by the tyoe of surface the robot is moving on. We first calculate the roll, yaw and pitch from the orientation information using the transformation formulas as shown below. We add these features to X_train_new and X_test_new (separately) and delete the orientation features (W,X,Y,Z). The rate of change in yaw,pitch and roll will be calculated at a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR TRAIN DATASET\n",
    "roll=np.zeros([X_train_new.shape[0],1])\n",
    "pitch=np.zeros([X_train_new.shape[0],1])\n",
    "yaw=np.zeros([X_train_new.shape[0],1])\n",
    "\n",
    "\n",
    "for i in range(X_train_new.shape[0]):\n",
    "  roll[i] = np.arctan2(2*(X_train_new[i,1]*X_train_new[i,2] + X_train_new[i,3]*X_train_new[i,0]),1 - 2*(X_train_new[i,2]*X_train_new[i,2] + X_train_new[i,3]*X_train_new[i,3]))\n",
    "  pitch[i] = np.arcsin(2*(X_train_new[i,1]*X_train_new[i,3] - X_train_new[i,0]*X_train_new[i,2]))\n",
    "  yaw[i] = np.arctan2(2*(X_train_new[i,1]*X_train_new[i,0] + X_train_new[i,2]*X_train_new[i,3]),1 - 2*(X_train_new[i,3]*X_train_new[i,3] + X_train_new[i,0]*X_train_new[i,0]))\n",
    "\n",
    "X_train_new=np.delete(X_train_new,[0,1,2,3], 1)\n",
    "X_train_new=np.concatenate((roll,pitch,yaw,X_train_new),axis=1)\n",
    "\n",
    "#FOR TEST DATA SET\n",
    "roll=np.zeros([X_test_new.shape[0],1])\n",
    "pitch=np.zeros([X_test_new.shape[0],1])\n",
    "yaw=np.zeros([X_test_new.shape[0],1])\n",
    "\n",
    "\n",
    "for i in range(X_test_new.shape[0]):\n",
    "  roll[i] = np.arctan2(2*(X_test_new[i,1]*X_test_new[i,2] + X_test_new[i,3]*X_test_new[i,0]),1 - 2*(X_test_new[i,2]*X_test_new[i,2] + X_test_new[i,3]*X_test_new[i,3]))\n",
    "  pitch[i] = np.arcsin(2*(X_test_new[i,1]*X_test_new[i,3] - X_test_new[i,0]*X_test_new[i,2]))\n",
    "  yaw[i] = np.arctan2(2*(X_test_new[i,1]*X_test_new[i,0] + X_test_new[i,2]*X_test_new[i,3]),1 - 2*(X_test_new[i,3]*X_test_new[i,3] + X_test_new[i,0]*X_test_new[i,0]))\n",
    "\n",
    "X_test_new=np.delete(X_test_new,[0,1,2,3], 1)\n",
    "X_test_new=np.concatenate((roll,pitch,yaw,X_test_new),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## **Step 2: Building the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The data should be reshaped in a 3D matrix to suit the 1D CNN input data shape. The first dimension is for the samples, the second for the timestamp, and the third for the featueres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train:  (3790, 128, 9)\n",
      "The shape of X_test:  (20, 128, 9)\n"
     ]
    }
   ],
   "source": [
    "nfeatures=X_train_new.shape[1]\n",
    "ntimestamp=128\n",
    "nsamples=3790\n",
    "X_3D_train=X_train_new[:,0].reshape(nsamples,ntimestamp)\n",
    "for i in range(nfeatures-1):\n",
    "  i=i+1\n",
    "  r=X_train_new[:,i].reshape(nsamples,ntimestamp)\n",
    "  X_3D_train=np.dstack((X_3D_train,r))\n",
    "print('The shape of X_train: ', X_3D_train.shape)\n",
    "\n",
    "nfeatures=X_test_new.shape[1]\n",
    "ntimestamp=128\n",
    "nsamples=20\n",
    "X_3D_test=X_test_new[:,0].reshape(nsamples,ntimestamp)\n",
    "for i in range(nfeatures-1):\n",
    "  i=i+1\n",
    "  r=X_test_new[:,i].reshape(nsamples,ntimestamp)\n",
    "  X_3D_test=np.dstack((X_3D_test,r))\n",
    "print('The shape of X_test: ', X_3D_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "As mentioned earlier, we need to include the rate of change for the yaw, pitch and roll as they are affected by the type of surface the robot is moving on. We calculated the roll, yaw and pitch earlier and added them to X_train_new and X_test_new. We will replace them with their rate of change instead. They are stored in the first three features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    rate = X_3D_train[:,:,i]\n",
    "    rate_c = np.copy(rate)\n",
    "    rate_c[:,1:] = rate_c[:,:-1]\n",
    "    rate = rate - rate_c\n",
    "    X_3D_train[:,:,i] = rate\n",
    "    \n",
    "for i in range(2):\n",
    "    rate = X_3D_test[:,:,i]\n",
    "    rate_c = np.copy(rate)\n",
    "    rate_c[:,1:] = rate_c[:,:-1]\n",
    "    rate = rate - rate_c\n",
    "    X_3D_test[:,:,i] = rate"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Another feature we think is important is the fft of the time series data. We believe that each surface will cause the robot to vibrate or oscillate with specific frequencies. Thus, we calculate the fft for all the timeseries features in X_train_new and X_test_new (separately) and add the fft of the features to the corresponding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of X_3D:  (3790, 128, 18)\n",
      "The size of X_3D:  (20, 128, 18)\n"
     ]
    }
   ],
   "source": [
    "from scipy import fftpack\n",
    "X_3Dfft = np.abs(np.fft.fft(X_3D_train,axis=1))\n",
    "#freqs = fftpack.fftfreq(len(x)) * f_s\n",
    "X_3D_train=np.dstack((X_3D_train,X_3Dfft))\n",
    "print('The size of X_3D: ', X_3D_train.shape)\n",
    "\n",
    "from scipy import fftpack\n",
    "X_3Dfft = np.abs(np.fft.fft(X_3D_test,axis=1))\n",
    "#freqs = fftpack.fftfreq(len(x)) * f_s\n",
    "X_3D_test=np.dstack((X_3D_test,X_3Dfft))\n",
    "print('The size of X_3D: ', X_3D_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We print the parameters of X_train_new. Number of: (features, timestamps and samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in Xtrain:  18\n",
      "Number of timestamps in Xtrain:  128\n",
      "Number of samples in Xtrain:  3790\n"
     ]
    }
   ],
   "source": [
    "nfeatures=X_3D_train.shape[2]\n",
    "ntimestamp=X_3D_train.shape[1]\n",
    "nsamples=X_3D_train.shape[0]\n",
    "\n",
    "print('Number of features in Xtrain: ', nfeatures)\n",
    "print('Number of timestamps in Xtrain: ', ntimestamp)\n",
    "print('Number of samples in Xtrain: ', nsamples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We standarize X_train_new and X_test_new separately by calculating the mean and standard deviation for each of the feautures across all samples, and then subtracting the mean and dividing by the standard deviation. Standarization can help the conv net to acheive better results by removing any effects resulted from different recording sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(nfeatures):\n",
    "    X_train_m = np.mean(X_3D_train[:,:,k])\n",
    "    X_train_sd = np.std(X_3D_train[:,:,k])\n",
    "    X_3D_train[:,:,k] = (X_3D_train[:,:,k]-X_train_m)/X_train_sd\n",
    "\n",
    "for k in range(nfeatures):\n",
    "    X_test_m = np.mean(X_3D_test[:,:,k])\n",
    "    X_test_sd = np.std(X_3D_test[:,:,k])\n",
    "    X_3D_test[:,:,k] = (X_3D_test[:,:,k]-X_test_m)/X_test_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Now, we create the 1D convnet model. I have tried to tune the number of layers, number of filters in each layer, the batch size and the dropout ratio to give the best validation accuracy. Removing the 256 filters layer resulted in a very poor accuracy. Adding more layers resulted in overfitting (high accuracy on training data but low on validation). Lower dropout ratio resulted in over fitting too. I added layers one by one and observed how the training and validation accuracy change over training. 15% of the training data is kept for the validation. The high dropout ration is to avoid overfitting during training. Also, I tried to minimize the complexity of the model by introducing enough layers that can achieve the max possible accuracy with the current features created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 2.7005 - accuracy: 0.1607\n",
      "Epoch 2/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 2.1149 - accuracy: 0.1570\n",
      "Epoch 3/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.9909 - accuracy: 0.1873\n",
      "Epoch 4/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.8757 - accuracy: 0.2728\n",
      "Epoch 5/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.8063 - accuracy: 0.3354\n",
      "Epoch 6/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.7610 - accuracy: 0.3559\n",
      "Epoch 7/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.6851 - accuracy: 0.3855\n",
      "Epoch 8/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 1.6620 - accuracy: 0.4042\n",
      "Epoch 9/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.6052 - accuracy: 0.4208\n",
      "Epoch 10/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.5743 - accuracy: 0.4230\n",
      "Epoch 11/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.5558 - accuracy: 0.4306\n",
      "Epoch 12/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.5244 - accuracy: 0.4425\n",
      "Epoch 13/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.5026 - accuracy: 0.4441\n",
      "Epoch 14/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.4551 - accuracy: 0.4646\n",
      "Epoch 15/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.4386 - accuracy: 0.4694\n",
      "Epoch 16/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.4055 - accuracy: 0.4747\n",
      "Epoch 17/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.3836 - accuracy: 0.4712\n",
      "Epoch 18/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.3564 - accuracy: 0.4865\n",
      "Epoch 19/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.3389 - accuracy: 0.4916\n",
      "Epoch 20/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.3094 - accuracy: 0.5029\n",
      "Epoch 21/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.2751 - accuracy: 0.5090\n",
      "Epoch 22/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.2654 - accuracy: 0.5256\n",
      "Epoch 23/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.2457 - accuracy: 0.5303\n",
      "Epoch 24/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.1853 - accuracy: 0.5538\n",
      "Epoch 25/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.1512 - accuracy: 0.5528\n",
      "Epoch 26/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.1146 - accuracy: 0.5805\n",
      "Epoch 27/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.0911 - accuracy: 0.5842\n",
      "Epoch 28/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.0284 - accuracy: 0.6153\n",
      "Epoch 29/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 1.0239 - accuracy: 0.6061\n",
      "Epoch 30/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.9806 - accuracy: 0.6266\n",
      "Epoch 31/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.9628 - accuracy: 0.6409\n",
      "Epoch 32/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.9225 - accuracy: 0.6594\n",
      "Epoch 33/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.9030 - accuracy: 0.6565\n",
      "Epoch 34/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.8580 - accuracy: 0.6789\n",
      "Epoch 35/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.8542 - accuracy: 0.6739\n",
      "Epoch 36/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.8260 - accuracy: 0.6953\n",
      "Epoch 37/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.8216 - accuracy: 0.6897\n",
      "Epoch 38/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7805 - accuracy: 0.7079\n",
      "Epoch 39/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7982 - accuracy: 0.6971\n",
      "Epoch 40/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7785 - accuracy: 0.7074\n",
      "Epoch 41/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7289 - accuracy: 0.7206\n",
      "Epoch 42/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7236 - accuracy: 0.7335\n",
      "Epoch 43/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.7164 - accuracy: 0.7298\n",
      "Epoch 44/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.7014 - accuracy: 0.7269\n",
      "Epoch 45/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.6784 - accuracy: 0.7464\n",
      "Epoch 46/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.6659 - accuracy: 0.7451\n",
      "Epoch 47/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.6411 - accuracy: 0.7530\n",
      "Epoch 48/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.6041 - accuracy: 0.7731\n",
      "Epoch 49/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.6073 - accuracy: 0.7704\n",
      "Epoch 50/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5969 - accuracy: 0.7707\n",
      "Epoch 51/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5894 - accuracy: 0.7789\n",
      "Epoch 52/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5501 - accuracy: 0.7850\n",
      "Epoch 53/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5742 - accuracy: 0.7821\n",
      "Epoch 54/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5496 - accuracy: 0.7960\n",
      "Epoch 55/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5224 - accuracy: 0.8011\n",
      "Epoch 56/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5297 - accuracy: 0.8013\n",
      "Epoch 57/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4984 - accuracy: 0.8077\n",
      "Epoch 58/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.5209 - accuracy: 0.7937\n",
      "Epoch 59/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4922 - accuracy: 0.8111\n",
      "Epoch 60/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4807 - accuracy: 0.8185\n",
      "Epoch 61/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4799 - accuracy: 0.8288\n",
      "Epoch 62/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4959 - accuracy: 0.8058\n",
      "Epoch 63/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4669 - accuracy: 0.8253\n",
      "Epoch 64/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4520 - accuracy: 0.8356\n",
      "Epoch 65/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4504 - accuracy: 0.8266\n",
      "Epoch 66/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4552 - accuracy: 0.8237\n",
      "Epoch 67/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4267 - accuracy: 0.8438\n",
      "Epoch 68/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4111 - accuracy: 0.8359\n",
      "Epoch 69/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4201 - accuracy: 0.8359\n",
      "Epoch 70/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4151 - accuracy: 0.8396\n",
      "Epoch 71/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.4099 - accuracy: 0.8430\n",
      "Epoch 72/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3976 - accuracy: 0.8565\n",
      "Epoch 73/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.4104 - accuracy: 0.8507\n",
      "Epoch 74/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3827 - accuracy: 0.8544\n",
      "Epoch 75/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3806 - accuracy: 0.8604\n",
      "Epoch 76/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3745 - accuracy: 0.8567\n",
      "Epoch 77/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3772 - accuracy: 0.8488\n",
      "Epoch 78/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3560 - accuracy: 0.8702\n",
      "Epoch 79/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3511 - accuracy: 0.8712\n",
      "Epoch 80/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3559 - accuracy: 0.8612\n",
      "Epoch 81/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3508 - accuracy: 0.8620\n",
      "Epoch 82/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3563 - accuracy: 0.8710\n",
      "Epoch 83/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3531 - accuracy: 0.8697\n",
      "Epoch 84/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3291 - accuracy: 0.8710\n",
      "Epoch 85/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3135 - accuracy: 0.8807\n",
      "Epoch 86/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3297 - accuracy: 0.8752\n",
      "Epoch 87/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3171 - accuracy: 0.8818\n",
      "Epoch 88/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.3159 - accuracy: 0.8789\n",
      "Epoch 89/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3106 - accuracy: 0.8747\n",
      "Epoch 90/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2855 - accuracy: 0.8868\n",
      "Epoch 91/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3100 - accuracy: 0.8823\n",
      "Epoch 92/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2959 - accuracy: 0.8858\n",
      "Epoch 93/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3008 - accuracy: 0.8892\n",
      "Epoch 94/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3024 - accuracy: 0.8847\n",
      "Epoch 95/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3054 - accuracy: 0.8784\n",
      "Epoch 96/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3096 - accuracy: 0.8807\n",
      "Epoch 97/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.3001 - accuracy: 0.8910\n",
      "Epoch 98/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.2810 - accuracy: 0.8921\n",
      "Epoch 99/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2808 - accuracy: 0.8937\n",
      "Epoch 100/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2873 - accuracy: 0.8905\n",
      "Epoch 101/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2917 - accuracy: 0.8916\n",
      "Epoch 102/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2921 - accuracy: 0.8894\n",
      "Epoch 103/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2773 - accuracy: 0.8902\n",
      "Epoch 104/600\n",
      "3790/3790 [==============================] - 14s 4ms/step - loss: 0.2792 - accuracy: 0.8942\n",
      "Epoch 105/600\n",
      "3790/3790 [==============================] - 21s 5ms/step - loss: 0.2711 - accuracy: 0.9000\n",
      "Epoch 106/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2632 - accuracy: 0.8939\n",
      "Epoch 107/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2471 - accuracy: 0.9063\n",
      "Epoch 108/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2594 - accuracy: 0.9008\n",
      "Epoch 109/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2489 - accuracy: 0.9024\n",
      "Epoch 110/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2550 - accuracy: 0.8971\n",
      "Epoch 111/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2528 - accuracy: 0.9087\n",
      "Epoch 112/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2622 - accuracy: 0.9016\n",
      "Epoch 113/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2580 - accuracy: 0.9034\n",
      "Epoch 114/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2605 - accuracy: 0.9040\n",
      "Epoch 115/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2519 - accuracy: 0.9100\n",
      "Epoch 116/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2538 - accuracy: 0.9058\n",
      "Epoch 117/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2452 - accuracy: 0.9045\n",
      "Epoch 118/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2460 - accuracy: 0.9069\n",
      "Epoch 119/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2399 - accuracy: 0.9077\n",
      "Epoch 120/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2322 - accuracy: 0.9100\n",
      "Epoch 121/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2398 - accuracy: 0.9092\n",
      "Epoch 122/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2253 - accuracy: 0.9172\n",
      "Epoch 123/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2383 - accuracy: 0.9047\n",
      "Epoch 124/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2083 - accuracy: 0.9261\n",
      "Epoch 125/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2111 - accuracy: 0.9201\n",
      "Epoch 126/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2034 - accuracy: 0.9222\n",
      "Epoch 127/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2208 - accuracy: 0.9137\n",
      "Epoch 128/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2176 - accuracy: 0.9190\n",
      "Epoch 129/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2140 - accuracy: 0.9219\n",
      "Epoch 130/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2029 - accuracy: 0.9245\n",
      "Epoch 131/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2127 - accuracy: 0.9261\n",
      "Epoch 132/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2115 - accuracy: 0.9224\n",
      "Epoch 133/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2123 - accuracy: 0.9206\n",
      "Epoch 134/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2224 - accuracy: 0.9182\n",
      "Epoch 135/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2239 - accuracy: 0.9166\n",
      "Epoch 136/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1974 - accuracy: 0.9222\n",
      "Epoch 137/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1993 - accuracy: 0.9243\n",
      "Epoch 138/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2103 - accuracy: 0.9187\n",
      "Epoch 139/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1975 - accuracy: 0.9274\n",
      "Epoch 140/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2115 - accuracy: 0.9193\n",
      "Epoch 141/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2042 - accuracy: 0.9248\n",
      "Epoch 142/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.2088 - accuracy: 0.9245\n",
      "Epoch 143/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1856 - accuracy: 0.9269\n",
      "Epoch 144/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1729 - accuracy: 0.9327\n",
      "Epoch 145/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1788 - accuracy: 0.9311\n",
      "Epoch 146/600\n",
      "3790/3790 [==============================] - 16s 4ms/step - loss: 0.1813 - accuracy: 0.9346\n",
      "Epoch 147/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1847 - accuracy: 0.9338\n",
      "Epoch 148/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1920 - accuracy: 0.9327\n",
      "Epoch 149/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1826 - accuracy: 0.9314\n",
      "Epoch 150/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1928 - accuracy: 0.9272\n",
      "Epoch 151/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1897 - accuracy: 0.9327\n",
      "Epoch 152/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1806 - accuracy: 0.9309\n",
      "Epoch 153/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1879 - accuracy: 0.9272\n",
      "Epoch 154/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.2068 - accuracy: 0.9293\n",
      "Epoch 155/600\n",
      "3790/3790 [==============================] - 24s 6ms/step - loss: 0.1846 - accuracy: 0.9314\n",
      "Epoch 156/600\n",
      "3790/3790 [==============================] - 15s 4ms/step - loss: 0.2122 - accuracy: 0.9224\n",
      "Epoch 157/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1864 - accuracy: 0.9327\n",
      "Epoch 158/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1913 - accuracy: 0.9338\n",
      "Epoch 159/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1538 - accuracy: 0.9435\n",
      "Epoch 160/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1715 - accuracy: 0.9338\n",
      "Epoch 161/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1678 - accuracy: 0.9375\n",
      "Epoch 162/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1573 - accuracy: 0.9414\n",
      "Epoch 163/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1587 - accuracy: 0.9409\n",
      "Epoch 164/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1450 - accuracy: 0.9475\n",
      "Epoch 165/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1519 - accuracy: 0.9412\n",
      "Epoch 166/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1477 - accuracy: 0.9483\n",
      "Epoch 167/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1457 - accuracy: 0.9417\n",
      "Epoch 168/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1570 - accuracy: 0.9430\n",
      "Epoch 169/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1765 - accuracy: 0.9340\n",
      "Epoch 170/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1609 - accuracy: 0.9377\n",
      "Epoch 171/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1493 - accuracy: 0.9493\n",
      "Epoch 172/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1473 - accuracy: 0.9417\n",
      "Epoch 173/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1530 - accuracy: 0.9396\n",
      "Epoch 174/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1438 - accuracy: 0.9430\n",
      "Epoch 175/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1506 - accuracy: 0.9488\n",
      "Epoch 176/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1554 - accuracy: 0.9449\n",
      "Epoch 177/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1707 - accuracy: 0.9422\n",
      "Epoch 178/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1357 - accuracy: 0.9475\n",
      "Epoch 179/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1478 - accuracy: 0.9438\n",
      "Epoch 180/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1511 - accuracy: 0.9396\n",
      "Epoch 181/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1757 - accuracy: 0.9377\n",
      "Epoch 182/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1433 - accuracy: 0.9449\n",
      "Epoch 183/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1334 - accuracy: 0.9483\n",
      "Epoch 184/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1473 - accuracy: 0.9470\n",
      "Epoch 185/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1506 - accuracy: 0.9391\n",
      "Epoch 186/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1375 - accuracy: 0.9483\n",
      "Epoch 187/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1473 - accuracy: 0.9441\n",
      "Epoch 188/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1348 - accuracy: 0.9470\n",
      "Epoch 189/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1388 - accuracy: 0.9425\n",
      "Epoch 190/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1507 - accuracy: 0.9459\n",
      "Epoch 191/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1441 - accuracy: 0.9443\n",
      "Epoch 192/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1534 - accuracy: 0.9462\n",
      "Epoch 193/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1589 - accuracy: 0.9449\n",
      "Epoch 194/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1468 - accuracy: 0.9454\n",
      "Epoch 195/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1674 - accuracy: 0.9446\n",
      "Epoch 196/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1511 - accuracy: 0.9443\n",
      "Epoch 197/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1459 - accuracy: 0.9464\n",
      "Epoch 198/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1540 - accuracy: 0.9449\n",
      "Epoch 199/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1197 - accuracy: 0.9522\n",
      "Epoch 200/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1183 - accuracy: 0.9554\n",
      "Epoch 201/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1433 - accuracy: 0.9478\n",
      "Epoch 202/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1549 - accuracy: 0.9446\n",
      "Epoch 203/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1322 - accuracy: 0.9501\n",
      "Epoch 204/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1435 - accuracy: 0.9512\n",
      "Epoch 205/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1297 - accuracy: 0.9517\n",
      "Epoch 206/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1348 - accuracy: 0.9557\n",
      "Epoch 207/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1405 - accuracy: 0.9464\n",
      "Epoch 208/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1385 - accuracy: 0.9459\n",
      "Epoch 209/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1380 - accuracy: 0.9480\n",
      "Epoch 210/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1434 - accuracy: 0.9406\n",
      "Epoch 211/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1549 - accuracy: 0.9383\n",
      "Epoch 212/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1527 - accuracy: 0.9435\n",
      "Epoch 213/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1349 - accuracy: 0.9470\n",
      "Epoch 214/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1192 - accuracy: 0.9570\n",
      "Epoch 215/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1272 - accuracy: 0.9549\n",
      "Epoch 216/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1417 - accuracy: 0.9496\n",
      "Epoch 217/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1179 - accuracy: 0.9549\n",
      "Epoch 218/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1210 - accuracy: 0.9557\n",
      "Epoch 219/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1170 - accuracy: 0.9517\n",
      "Epoch 220/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1082 - accuracy: 0.9588\n",
      "Epoch 221/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1114 - accuracy: 0.9599\n",
      "Epoch 222/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1271 - accuracy: 0.9483\n",
      "Epoch 223/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1184 - accuracy: 0.9557\n",
      "Epoch 224/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1180 - accuracy: 0.9525\n",
      "Epoch 225/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1178 - accuracy: 0.9588\n",
      "Epoch 226/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0987 - accuracy: 0.9623\n",
      "Epoch 227/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1124 - accuracy: 0.9575\n",
      "Epoch 228/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1102 - accuracy: 0.9580\n",
      "Epoch 229/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1140 - accuracy: 0.9536\n",
      "Epoch 230/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1237 - accuracy: 0.9573\n",
      "Epoch 231/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1210 - accuracy: 0.9607\n",
      "Epoch 232/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1148 - accuracy: 0.9596\n",
      "Epoch 233/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1126 - accuracy: 0.9607\n",
      "Epoch 234/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1083 - accuracy: 0.9586\n",
      "Epoch 235/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1072 - accuracy: 0.9588\n",
      "Epoch 236/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1083 - accuracy: 0.9575\n",
      "Epoch 237/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1137 - accuracy: 0.9551\n",
      "Epoch 238/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1095 - accuracy: 0.9612\n",
      "Epoch 239/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1097 - accuracy: 0.9578\n",
      "Epoch 240/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1065 - accuracy: 0.9591\n",
      "Epoch 241/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1120 - accuracy: 0.9607\n",
      "Epoch 242/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1073 - accuracy: 0.9578\n",
      "Epoch 243/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1071 - accuracy: 0.9628\n",
      "Epoch 244/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1076 - accuracy: 0.9609\n",
      "Epoch 245/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1121 - accuracy: 0.9588\n",
      "Epoch 246/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1031 - accuracy: 0.9583\n",
      "Epoch 247/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1083 - accuracy: 0.9583\n",
      "Epoch 248/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1041 - accuracy: 0.9607\n",
      "Epoch 249/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1069 - accuracy: 0.9602\n",
      "Epoch 250/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0975 - accuracy: 0.9641\n",
      "Epoch 251/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1085 - accuracy: 0.9586\n",
      "Epoch 252/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1083 - accuracy: 0.9570\n",
      "Epoch 253/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1061 - accuracy: 0.9602\n",
      "Epoch 254/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1024 - accuracy: 0.9609\n",
      "Epoch 255/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0966 - accuracy: 0.9631\n",
      "Epoch 256/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1012 - accuracy: 0.9612\n",
      "Epoch 257/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1040 - accuracy: 0.9639\n",
      "Epoch 258/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0964 - accuracy: 0.9615\n",
      "Epoch 259/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0965 - accuracy: 0.9652\n",
      "Epoch 260/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0899 - accuracy: 0.9623\n",
      "Epoch 261/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0999 - accuracy: 0.9617\n",
      "Epoch 262/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1134 - accuracy: 0.9559\n",
      "Epoch 263/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1000 - accuracy: 0.9631\n",
      "Epoch 264/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1079 - accuracy: 0.9623\n",
      "Epoch 265/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1012 - accuracy: 0.9623\n",
      "Epoch 266/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1089 - accuracy: 0.9607\n",
      "Epoch 267/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1003 - accuracy: 0.9628\n",
      "Epoch 268/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0952 - accuracy: 0.9633\n",
      "Epoch 269/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0955 - accuracy: 0.9649\n",
      "Epoch 270/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0906 - accuracy: 0.9660\n",
      "Epoch 271/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0997 - accuracy: 0.9675\n",
      "Epoch 272/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0820 - accuracy: 0.9712\n",
      "Epoch 273/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0875 - accuracy: 0.9699\n",
      "Epoch 274/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1042 - accuracy: 0.9594\n",
      "Epoch 275/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0927 - accuracy: 0.9657\n",
      "Epoch 276/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0986 - accuracy: 0.9665\n",
      "Epoch 277/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1013 - accuracy: 0.9636\n",
      "Epoch 278/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0945 - accuracy: 0.9660\n",
      "Epoch 279/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0989 - accuracy: 0.9620\n",
      "Epoch 280/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0876 - accuracy: 0.9665\n",
      "Epoch 281/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0842 - accuracy: 0.9683\n",
      "Epoch 282/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0872 - accuracy: 0.9660\n",
      "Epoch 283/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0821 - accuracy: 0.9670\n",
      "Epoch 284/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0863 - accuracy: 0.9668\n",
      "Epoch 285/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0757 - accuracy: 0.9704\n",
      "Epoch 286/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0968 - accuracy: 0.9694\n",
      "Epoch 287/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0815 - accuracy: 0.9699\n",
      "Epoch 288/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0841 - accuracy: 0.9710\n",
      "Epoch 289/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0867 - accuracy: 0.9681\n",
      "Epoch 290/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0863 - accuracy: 0.9686\n",
      "Epoch 291/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1007 - accuracy: 0.9633\n",
      "Epoch 292/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0946 - accuracy: 0.9675\n",
      "Epoch 293/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0712 - accuracy: 0.9765\n",
      "Epoch 294/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0909 - accuracy: 0.9704\n",
      "Epoch 295/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1029 - accuracy: 0.9580\n",
      "Epoch 296/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0964 - accuracy: 0.9675\n",
      "Epoch 297/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1096 - accuracy: 0.9615\n",
      "Epoch 298/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1012 - accuracy: 0.9612\n",
      "Epoch 299/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1021 - accuracy: 0.9662\n",
      "Epoch 300/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0900 - accuracy: 0.9660\n",
      "Epoch 301/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0898 - accuracy: 0.9702\n",
      "Epoch 302/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0874 - accuracy: 0.9699\n",
      "Epoch 303/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0847 - accuracy: 0.9670\n",
      "Epoch 304/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0802 - accuracy: 0.9712\n",
      "Epoch 305/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0971 - accuracy: 0.9665\n",
      "Epoch 306/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0878 - accuracy: 0.9678\n",
      "Epoch 307/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0805 - accuracy: 0.9757\n",
      "Epoch 308/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0870 - accuracy: 0.9675\n",
      "Epoch 309/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0844 - accuracy: 0.9668\n",
      "Epoch 310/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0800 - accuracy: 0.9720\n",
      "Epoch 311/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0909 - accuracy: 0.9681\n",
      "Epoch 312/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0986 - accuracy: 0.9612\n",
      "Epoch 313/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0918 - accuracy: 0.9662\n",
      "Epoch 314/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0799 - accuracy: 0.9678\n",
      "Epoch 315/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0898 - accuracy: 0.9668\n",
      "Epoch 316/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0845 - accuracy: 0.9665\n",
      "Epoch 317/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1049 - accuracy: 0.9623\n",
      "Epoch 318/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0959 - accuracy: 0.9681\n",
      "Epoch 319/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1006 - accuracy: 0.9594\n",
      "Epoch 320/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0857 - accuracy: 0.9665\n",
      "Epoch 321/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1026 - accuracy: 0.9628\n",
      "Epoch 322/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0904 - accuracy: 0.9707\n",
      "Epoch 323/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0771 - accuracy: 0.9686\n",
      "Epoch 324/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0824 - accuracy: 0.9673\n",
      "Epoch 325/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0799 - accuracy: 0.9718\n",
      "Epoch 326/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0769 - accuracy: 0.9726\n",
      "Epoch 327/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0903 - accuracy: 0.9668\n",
      "Epoch 328/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0937 - accuracy: 0.9657\n",
      "Epoch 329/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0833 - accuracy: 0.9699\n",
      "Epoch 330/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0792 - accuracy: 0.9683\n",
      "Epoch 331/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0814 - accuracy: 0.9707\n",
      "Epoch 332/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0734 - accuracy: 0.9728\n",
      "Epoch 333/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0910 - accuracy: 0.9710\n",
      "Epoch 334/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0958 - accuracy: 0.9681\n",
      "Epoch 335/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0819 - accuracy: 0.9683\n",
      "Epoch 336/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0865 - accuracy: 0.9689\n",
      "Epoch 337/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0846 - accuracy: 0.9699\n",
      "Epoch 338/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0793 - accuracy: 0.9704\n",
      "Epoch 339/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0712 - accuracy: 0.9707\n",
      "Epoch 340/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0825 - accuracy: 0.9720\n",
      "Epoch 341/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0778 - accuracy: 0.9710\n",
      "Epoch 342/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0713 - accuracy: 0.9691\n",
      "Epoch 343/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0748 - accuracy: 0.9699\n",
      "Epoch 344/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0767 - accuracy: 0.9728\n",
      "Epoch 345/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0708 - accuracy: 0.9728\n",
      "Epoch 346/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.1012 - accuracy: 0.9662\n",
      "Epoch 347/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0934 - accuracy: 0.9678\n",
      "Epoch 348/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0832 - accuracy: 0.9720\n",
      "Epoch 349/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0737 - accuracy: 0.9755\n",
      "Epoch 350/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0763 - accuracy: 0.9718\n",
      "Epoch 351/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0730 - accuracy: 0.9747\n",
      "Epoch 352/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0776 - accuracy: 0.9720\n",
      "Epoch 353/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0919 - accuracy: 0.9760\n",
      "Epoch 354/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0758 - accuracy: 0.9744\n",
      "Epoch 355/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0965 - accuracy: 0.9633\n",
      "Epoch 356/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0939 - accuracy: 0.9675\n",
      "Epoch 357/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0795 - accuracy: 0.9739\n",
      "Epoch 358/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0765 - accuracy: 0.9712\n",
      "Epoch 359/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0763 - accuracy: 0.9718\n",
      "Epoch 360/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 361/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0701 - accuracy: 0.9747\n",
      "Epoch 362/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0705 - accuracy: 0.9715\n",
      "Epoch 363/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0706 - accuracy: 0.9744\n",
      "Epoch 364/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0709 - accuracy: 0.9749\n",
      "Epoch 365/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0648 - accuracy: 0.9744\n",
      "Epoch 366/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0771 - accuracy: 0.9718\n",
      "Epoch 367/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0768 - accuracy: 0.9739\n",
      "Epoch 368/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0826 - accuracy: 0.9739\n",
      "Epoch 369/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0968 - accuracy: 0.9670\n",
      "Epoch 370/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0986 - accuracy: 0.9646\n",
      "Epoch 371/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.1018 - accuracy: 0.9657\n",
      "Epoch 372/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0801 - accuracy: 0.9720\n",
      "Epoch 373/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0724 - accuracy: 0.9723\n",
      "Epoch 374/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0742 - accuracy: 0.9697\n",
      "Epoch 375/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0775 - accuracy: 0.9710\n",
      "Epoch 376/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0721 - accuracy: 0.9749\n",
      "Epoch 377/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0608 - accuracy: 0.9781\n",
      "Epoch 378/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0632 - accuracy: 0.9773\n",
      "Epoch 379/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0695 - accuracy: 0.9781\n",
      "Epoch 380/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0690 - accuracy: 0.9747\n",
      "Epoch 381/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0618 - accuracy: 0.9741\n",
      "Epoch 382/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0694 - accuracy: 0.9776\n",
      "Epoch 383/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0603 - accuracy: 0.9792\n",
      "Epoch 384/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0682 - accuracy: 0.9770\n",
      "Epoch 385/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0743 - accuracy: 0.9747\n",
      "Epoch 386/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0765 - accuracy: 0.9718\n",
      "Epoch 387/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0654 - accuracy: 0.9752\n",
      "Epoch 388/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0689 - accuracy: 0.9760\n",
      "Epoch 389/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0711 - accuracy: 0.9734\n",
      "Epoch 390/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0863 - accuracy: 0.9736\n",
      "Epoch 391/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0675 - accuracy: 0.9752\n",
      "Epoch 392/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0628 - accuracy: 0.9786\n",
      "Epoch 393/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0685 - accuracy: 0.9760\n",
      "Epoch 394/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0689 - accuracy: 0.9749\n",
      "Epoch 395/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0802 - accuracy: 0.9736\n",
      "Epoch 396/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0739 - accuracy: 0.9741\n",
      "Epoch 397/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0682 - accuracy: 0.9765\n",
      "Epoch 398/600\n",
      "3790/3790 [==============================] - 21s 6ms/step - loss: 0.0675 - accuracy: 0.9752\n",
      "Epoch 399/600\n",
      "3790/3790 [==============================] - 13s 4ms/step - loss: 0.0704 - accuracy: 0.9741\n",
      "Epoch 400/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0763 - accuracy: 0.9710\n",
      "Epoch 401/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0831 - accuracy: 0.9734\n",
      "Epoch 402/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0689 - accuracy: 0.9768\n",
      "Epoch 403/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0825 - accuracy: 0.9718\n",
      "Epoch 404/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0741 - accuracy: 0.9704\n",
      "Epoch 405/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0610 - accuracy: 0.9805\n",
      "Epoch 406/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0637 - accuracy: 0.9776\n",
      "Epoch 407/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0677 - accuracy: 0.9752\n",
      "Epoch 408/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0496 - accuracy: 0.9797\n",
      "Epoch 409/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0621 - accuracy: 0.9778\n",
      "Epoch 410/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0890 - accuracy: 0.9678\n",
      "Epoch 411/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0695 - accuracy: 0.9760\n",
      "Epoch 412/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0743 - accuracy: 0.9720\n",
      "Epoch 413/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0821 - accuracy: 0.9723\n",
      "Epoch 414/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0659 - accuracy: 0.9747\n",
      "Epoch 415/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0670 - accuracy: 0.9768\n",
      "Epoch 416/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0752 - accuracy: 0.9752\n",
      "Epoch 417/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0688 - accuracy: 0.9773\n",
      "Epoch 418/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0792 - accuracy: 0.9720\n",
      "Epoch 419/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0601 - accuracy: 0.9770\n",
      "Epoch 420/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0755 - accuracy: 0.9707\n",
      "Epoch 421/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0645 - accuracy: 0.9763\n",
      "Epoch 422/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0589 - accuracy: 0.9781\n",
      "Epoch 423/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0585 - accuracy: 0.9794\n",
      "Epoch 424/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0556 - accuracy: 0.9778\n",
      "Epoch 425/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0622 - accuracy: 0.9749\n",
      "Epoch 426/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0641 - accuracy: 0.9752\n",
      "Epoch 427/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0604 - accuracy: 0.9773\n",
      "Epoch 428/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0688 - accuracy: 0.9781\n",
      "Epoch 429/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0584 - accuracy: 0.9792\n",
      "Epoch 430/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0767 - accuracy: 0.9731\n",
      "Epoch 431/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0842 - accuracy: 0.9763\n",
      "Epoch 432/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0739 - accuracy: 0.9736\n",
      "Epoch 433/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0661 - accuracy: 0.9778\n",
      "Epoch 434/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0631 - accuracy: 0.9765\n",
      "Epoch 435/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0718 - accuracy: 0.9760\n",
      "Epoch 436/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0659 - accuracy: 0.9768\n",
      "Epoch 437/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0658 - accuracy: 0.9781\n",
      "Epoch 438/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0707 - accuracy: 0.9765\n",
      "Epoch 439/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0809 - accuracy: 0.9702\n",
      "Epoch 440/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0695 - accuracy: 0.9770\n",
      "Epoch 441/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0716 - accuracy: 0.9765\n",
      "Epoch 442/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0679 - accuracy: 0.9773\n",
      "Epoch 443/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0586 - accuracy: 0.9799\n",
      "Epoch 444/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0728 - accuracy: 0.9712\n",
      "Epoch 445/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0507 - accuracy: 0.9805\n",
      "Epoch 446/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0577 - accuracy: 0.9802\n",
      "Epoch 447/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0651 - accuracy: 0.9781\n",
      "Epoch 448/600\n",
      "3790/3790 [==============================] - 23s 6ms/step - loss: 0.0810 - accuracy: 0.9747\n",
      "Epoch 449/600\n",
      "3790/3790 [==============================] - 23s 6ms/step - loss: 0.0715 - accuracy: 0.9773\n",
      "Epoch 450/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0627 - accuracy: 0.9778\n",
      "Epoch 451/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0617 - accuracy: 0.9778\n",
      "Epoch 452/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0566 - accuracy: 0.9784\n",
      "Epoch 453/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0595 - accuracy: 0.9810\n",
      "Epoch 454/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0702 - accuracy: 0.9755\n",
      "Epoch 455/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0766 - accuracy: 0.9763\n",
      "Epoch 456/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0560 - accuracy: 0.9805\n",
      "Epoch 457/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0690 - accuracy: 0.9765\n",
      "Epoch 458/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0544 - accuracy: 0.9797\n",
      "Epoch 459/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0621 - accuracy: 0.9789\n",
      "Epoch 460/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0725 - accuracy: 0.9755\n",
      "Epoch 461/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0775 - accuracy: 0.9739\n",
      "Epoch 462/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0811 - accuracy: 0.9734\n",
      "Epoch 463/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0691 - accuracy: 0.9757\n",
      "Epoch 464/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0686 - accuracy: 0.9789\n",
      "Epoch 465/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0635 - accuracy: 0.9778\n",
      "Epoch 466/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0607 - accuracy: 0.9789\n",
      "Epoch 467/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0744 - accuracy: 0.9749\n",
      "Epoch 468/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0463 - accuracy: 0.9844\n",
      "Epoch 469/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0549 - accuracy: 0.9810\n",
      "Epoch 470/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0435 - accuracy: 0.9836\n",
      "Epoch 471/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0622 - accuracy: 0.9760\n",
      "Epoch 472/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0583 - accuracy: 0.9807\n",
      "Epoch 473/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0632 - accuracy: 0.9781\n",
      "Epoch 474/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0757 - accuracy: 0.9736\n",
      "Epoch 475/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0500 - accuracy: 0.9810\n",
      "Epoch 476/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0572 - accuracy: 0.9797\n",
      "Epoch 477/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0497 - accuracy: 0.9818\n",
      "Epoch 478/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0554 - accuracy: 0.9765\n",
      "Epoch 479/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0726 - accuracy: 0.9734\n",
      "Epoch 480/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0496 - accuracy: 0.9831\n",
      "Epoch 481/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0491 - accuracy: 0.9823\n",
      "Epoch 482/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0508 - accuracy: 0.9826\n",
      "Epoch 483/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0511 - accuracy: 0.9813\n",
      "Epoch 484/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0574 - accuracy: 0.9799\n",
      "Epoch 485/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0497 - accuracy: 0.9842\n",
      "Epoch 486/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0614 - accuracy: 0.9794\n",
      "Epoch 487/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0565 - accuracy: 0.9810\n",
      "Epoch 488/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0564 - accuracy: 0.9797\n",
      "Epoch 489/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0471 - accuracy: 0.9821\n",
      "Epoch 490/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0451 - accuracy: 0.9818\n",
      "Epoch 491/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0538 - accuracy: 0.9836\n",
      "Epoch 492/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0485 - accuracy: 0.9834\n",
      "Epoch 493/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0519 - accuracy: 0.9818\n",
      "Epoch 494/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0491 - accuracy: 0.9818\n",
      "Epoch 495/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0492 - accuracy: 0.9823\n",
      "Epoch 496/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0518 - accuracy: 0.9805\n",
      "Epoch 497/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0503 - accuracy: 0.9823\n",
      "Epoch 498/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0545 - accuracy: 0.9815\n",
      "Epoch 499/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0539 - accuracy: 0.9797\n",
      "Epoch 500/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0513 - accuracy: 0.9850\n",
      "Epoch 501/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0624 - accuracy: 0.9789\n",
      "Epoch 502/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0592 - accuracy: 0.9807\n",
      "Epoch 503/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0462 - accuracy: 0.9823\n",
      "Epoch 504/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0554 - accuracy: 0.9789\n",
      "Epoch 505/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0809 - accuracy: 0.9773\n",
      "Epoch 506/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0598 - accuracy: 0.9813\n",
      "Epoch 507/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0641 - accuracy: 0.9799\n",
      "Epoch 508/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0702 - accuracy: 0.9776\n",
      "Epoch 509/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0557 - accuracy: 0.9826\n",
      "Epoch 510/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0500 - accuracy: 0.9802\n",
      "Epoch 511/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0626 - accuracy: 0.9797\n",
      "Epoch 512/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0594 - accuracy: 0.9797\n",
      "Epoch 513/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0514 - accuracy: 0.9844\n",
      "Epoch 514/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0450 - accuracy: 0.9818\n",
      "Epoch 515/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0543 - accuracy: 0.9794\n",
      "Epoch 516/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0552 - accuracy: 0.9786\n",
      "Epoch 517/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0607 - accuracy: 0.9792\n",
      "Epoch 518/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0544 - accuracy: 0.9807\n",
      "Epoch 519/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0679 - accuracy: 0.9741\n",
      "Epoch 520/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0603 - accuracy: 0.9797\n",
      "Epoch 521/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0653 - accuracy: 0.9786\n",
      "Epoch 522/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0540 - accuracy: 0.9813\n",
      "Epoch 523/600\n",
      "3790/3790 [==============================] - 14s 4ms/step - loss: 0.0684 - accuracy: 0.9765\n",
      "Epoch 524/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0579 - accuracy: 0.9781\n",
      "Epoch 525/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0627 - accuracy: 0.9805\n",
      "Epoch 526/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0653 - accuracy: 0.9773\n",
      "Epoch 527/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0604 - accuracy: 0.9802\n",
      "Epoch 528/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0474 - accuracy: 0.9813\n",
      "Epoch 529/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0715 - accuracy: 0.9786\n",
      "Epoch 530/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0635 - accuracy: 0.9797\n",
      "Epoch 531/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0517 - accuracy: 0.9834\n",
      "Epoch 532/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0542 - accuracy: 0.9799\n",
      "Epoch 533/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0409 - accuracy: 0.9858\n",
      "Epoch 534/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0581 - accuracy: 0.9794\n",
      "Epoch 535/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0378 - accuracy: 0.9858\n",
      "Epoch 536/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0430 - accuracy: 0.9850\n",
      "Epoch 537/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0418 - accuracy: 0.9850\n",
      "Epoch 538/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0441 - accuracy: 0.9852\n",
      "Epoch 539/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0502 - accuracy: 0.9818\n",
      "Epoch 540/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0450 - accuracy: 0.9852\n",
      "Epoch 541/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0504 - accuracy: 0.9836\n",
      "Epoch 542/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0603 - accuracy: 0.9802\n",
      "Epoch 543/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0498 - accuracy: 0.9810\n",
      "Epoch 544/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0470 - accuracy: 0.9844\n",
      "Epoch 545/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0444 - accuracy: 0.9855\n",
      "Epoch 546/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0489 - accuracy: 0.9834\n",
      "Epoch 547/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0455 - accuracy: 0.9807\n",
      "Epoch 548/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0524 - accuracy: 0.9826\n",
      "Epoch 549/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0390 - accuracy: 0.9858\n",
      "Epoch 550/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0452 - accuracy: 0.9844\n",
      "Epoch 551/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0491 - accuracy: 0.9826\n",
      "Epoch 552/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 553/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0488 - accuracy: 0.9802\n",
      "Epoch 554/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0497 - accuracy: 0.9834\n",
      "Epoch 555/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0501 - accuracy: 0.9842\n",
      "Epoch 556/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0376 - accuracy: 0.9865\n",
      "Epoch 557/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0563 - accuracy: 0.9797\n",
      "Epoch 558/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0574 - accuracy: 0.9794\n",
      "Epoch 559/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0428 - accuracy: 0.9865\n",
      "Epoch 560/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0418 - accuracy: 0.9842\n",
      "Epoch 561/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0542 - accuracy: 0.9839\n",
      "Epoch 562/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0482 - accuracy: 0.9839\n",
      "Epoch 563/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0586 - accuracy: 0.9821\n",
      "Epoch 564/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0466 - accuracy: 0.9828\n",
      "Epoch 565/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0502 - accuracy: 0.9842\n",
      "Epoch 566/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0489 - accuracy: 0.9847\n",
      "Epoch 567/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0502 - accuracy: 0.9834\n",
      "Epoch 568/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0493 - accuracy: 0.9836\n",
      "Epoch 569/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0531 - accuracy: 0.9773\n",
      "Epoch 570/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0558 - accuracy: 0.9807\n",
      "Epoch 571/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0408 - accuracy: 0.9844\n",
      "Epoch 572/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0456 - accuracy: 0.9831\n",
      "Epoch 573/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0571 - accuracy: 0.9823\n",
      "Epoch 574/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0487 - accuracy: 0.9828\n",
      "Epoch 575/600\n",
      "3790/3790 [==============================] - 13s 3ms/step - loss: 0.0514 - accuracy: 0.9842\n",
      "Epoch 576/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0492 - accuracy: 0.9834\n",
      "Epoch 577/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0579 - accuracy: 0.9821\n",
      "Epoch 578/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0522 - accuracy: 0.9826\n",
      "Epoch 579/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0507 - accuracy: 0.9852\n",
      "Epoch 580/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0501 - accuracy: 0.9836\n",
      "Epoch 581/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0585 - accuracy: 0.9797\n",
      "Epoch 582/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0438 - accuracy: 0.9823\n",
      "Epoch 583/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0572 - accuracy: 0.9815\n",
      "Epoch 584/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0516 - accuracy: 0.9834\n",
      "Epoch 585/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0445 - accuracy: 0.9834\n",
      "Epoch 586/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0482 - accuracy: 0.9823\n",
      "Epoch 587/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0460 - accuracy: 0.9850\n",
      "Epoch 588/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0429 - accuracy: 0.9852\n",
      "Epoch 589/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0451 - accuracy: 0.9839\n",
      "Epoch 590/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0354 - accuracy: 0.9887\n",
      "Epoch 591/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0365 - accuracy: 0.9892\n",
      "Epoch 592/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0418 - accuracy: 0.9847\n",
      "Epoch 593/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0376 - accuracy: 0.9868\n",
      "Epoch 594/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0404 - accuracy: 0.9858\n",
      "Epoch 595/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0365 - accuracy: 0.9879\n",
      "Epoch 596/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0521 - accuracy: 0.9855\n",
      "Epoch 597/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0404 - accuracy: 0.9844\n",
      "Epoch 598/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0369 - accuracy: 0.9879\n",
      "Epoch 599/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0491 - accuracy: 0.9834\n",
      "Epoch 600/600\n",
      "3790/3790 [==============================] - 12s 3ms/step - loss: 0.0461 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "predict=np.zeros([y_test_new.shape[0],y_test_new.shape[1],3])\n",
    "for k in range(1):\n",
    "  verbose, epochs, batch_size = 1, 600, 512\n",
    "  model = Sequential()\n",
    "  model.add(Conv1D(filters=64, kernel_size=8, activation='relu', input_shape=(ntimestamp,nfeatures)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Conv1D(filters=128, kernel_size=8, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Conv1D(filters=256, kernel_size=8, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(MaxPooling1D(pool_size=1))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu')) \n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(y_train_new.shape[1], activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "  model.fit(X_3D_train, y_train_new, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "We calculate the accuracy by comparing the prediction vs ytest:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "predict=np.zeros([y_test_new.shape[0],y_test_new.shape[1],3])\n",
    "\n",
    "yhat=model.predict(X_3D_test)\n",
    "predict[:,:,k]=yhat\n",
    "\n",
    "#_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "\n",
    "yhat=np.mean(predict,axis=2)\n",
    "yhat_final = np.array(list(np.argmax(yhat,axis=1)))\n",
    "y_testt=np.argmax(y_test_new,axis=1)\n",
    "\n",
    "accuracy=np.mean(yhat_final==y_testt)\n",
    "print('The accuracy is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
